{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881bb80b",
   "metadata": {},
   "source": [
    "# Lecture 2: Matrix Calculus & Probability Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8f3150",
   "metadata": {},
   "source": [
    "### 1. Linear Algebra: Projections and Eigen-Analysis\n",
    "\n",
    "Projection can be define as finding the nearest point on a subspace to a given vector.\n",
    "\n",
    "Implementation: The Projection Matrix\n",
    "\n",
    "The projection of a vector $v$ onto the subspace spanned by the columns of matrix $X$ is given by the matrix $P=X(X^TX)^{−1}X^T$.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d94d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projected vector u: [-2.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a subspace (columns of X) and a vector v to project\n",
    "X = np.array([[5]]) # A 2D plane in 3D space\n",
    "v = np.array([5-7])\n",
    "\n",
    "# Calculate the Projection Matrix: P = X @ inv(XT @ X) @ XT\n",
    "XTX_inv = np.linalg.inv(X.T @ X)\n",
    "P = X @ XTX_inv @ X.T\n",
    "\n",
    "# The projected vector u\n",
    "u = P @ v\n",
    "print(f\"Projected vector u: {u}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991a9dbe",
   "metadata": {},
   "source": [
    "Eigenvalues and Volume\n",
    "\n",
    "The determinant of a matrix can be interpreted as the ratio of the volume of the output shape to the volume of the input shape. If a matrix is not full rank, it squashes the volume to zero, meaning at least one eigenvalue is zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb233f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues: [-0.43717104 11.43717104]\n",
      "Product of Eigenvalues: -4.999999999999997\n",
      "Determinant: -4.999999999999999\n"
     ]
    }
   ],
   "source": [
    "# Create a matrix A\n",
    "A = np.array([[5, 7], [5, 6]])\n",
    "\n",
    "# Calculate eigenvalues and determinant\n",
    "eigenvalues = np.linalg.eigvals(A)\n",
    "det_A = np.linalg.det(A)\n",
    "\n",
    "print(f\"Eigenvalues: {eigenvalues}\")\n",
    "print(f\"Product of Eigenvalues: {np.prod(eigenvalues)}\")\n",
    "print(f\"Determinant: {det_A}\") # Should match the product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3699550",
   "metadata": {},
   "source": [
    "### 2. Matrix Calculus and Convexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d547445",
   "metadata": {},
   "source": [
    "Lecture 2 introduces the gradient as the direction of steepest ascent and the Hessian as a way to characterize the \"shape\" of a function.\n",
    "\n",
    "Quadratic Forms and Definiteness\n",
    "\n",
    "A symmetric matrix A is positive definite (PD) if the quadratic form $x^T$ $Ax>0$ for all non-zero $x$. This corresponds to a bowl-shaped (convex) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44125ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A is: Positive Definite (Convex)\n"
     ]
    }
   ],
   "source": [
    "# Function to check definiteness via eigenvalues\n",
    "def check_definiteness(matrix):\n",
    "    vals = np.linalg.eigvals(matrix)\n",
    "    if np.all(vals > 0): return \"Positive Definite (Convex)\"\n",
    "    if np.all(vals >= 0): return \"Positive Semi-Definite\"\n",
    "    if np.all(vals < 0): return \"Negative Definite\"\n",
    "    return \"Indefinite (Saddle Points)\"\n",
    "\n",
    "# Example: A convex loss function surface\n",
    "A_convex = np.array([[6]])\n",
    "print(f\"Matrix A is: {check_definiteness(A_convex)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5606a7d",
   "metadata": {},
   "source": [
    "Common Gradient Identities\n",
    "\n",
    "The sources provide several key identities used in machine learning:\n",
    "\n",
    "• $∇_x(b^Tx)=b$\n",
    "\n",
    "• $∇_x(x^TAx)=2Ax$ (for symmetric $A$)\n",
    "\n",
    "• $∇_Alog∣A∣=A^{−1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c25aa6",
   "metadata": {},
   "source": [
    "### 3. Probability: Monte Carlo Estimation\n",
    "\n",
    "The lecture concludes with Expected Value and the Law of Large Numbers. The Monte Carlo estimate allows us to approximate an expectation by averaging random samples.\n",
    "\n",
    "Implementation: Law of Large Numbers\n",
    "\n",
    "To find $E[g(x)]$, we sample $x_i$ from a density $p(x)$ and compute $1/n∑g(x_i)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4037eb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo Estimate of E[x^2]: 1.018694184596239\n"
     ]
    }
   ],
   "source": [
    "# Let g(x) = x^2 and x be sampled from a standard normal distribution\n",
    "def g(x):\n",
    "    return x**2\n",
    "\n",
    "samples = np.random.normal(0, 1, 10000)\n",
    "monte_carlo_estimate = np.mean(g(samples))\n",
    "\n",
    "print(f\"Monte Carlo Estimate of E[x^2]: {monte_carlo_estimate}\")\n",
    "# For N(0,1), E[x^2] is the variance + mean^2 = 1 + 0 = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d19bf",
   "metadata": {},
   "source": [
    "Summary Analogy\n",
    "\n",
    "To visualize these concepts, imagine you are shining a flashlight (the matrix/operator) at a soccer ball (unit sphere). The shadow cast on the wall is an ellipsoid. The eigenvectors are the directions of the ellipsoid's axes, and the eigenvalues tell you how much the ball was stretched in those directions. If the shadow becomes a flat line, your matrix has \"squashed\" a dimension, its determinant is zero, and you have lost the ability to \"undo\" the transformation (no inverse)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs229_env (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
